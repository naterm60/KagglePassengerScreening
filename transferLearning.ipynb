{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Model Code for the </center>\n",
    "# <center>Department of Homeland Security </center>\n",
    "# <center>Passenger Screening Algorithm Challenge.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General imports and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.signal import medfilt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import resample\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "from scipy.misc import imsave\n",
    "from scipy.ndimage import imread\n",
    "from copy import deepcopy\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip3 install Cython\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(datetime.datetime.now()) + \"    Started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project-specific imports and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get project functions\n",
    "from CompetitionFileIOFunctions import initRootFolders, initLog, log, filenames, filePath, loadFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init root folders\n",
    "inCloud = True\n",
    "if inCloud:\n",
    "    # Working in the cloud.  (This was used only for embeding scans in 2D.)\n",
    "    # Will read scans from the bucket and save results in paths relative to notebook:\n",
    "    initRootFolders(bucketName='kaggle_passenger_screening123407', localIOPath='')\n",
    "else:\n",
    "    # Working on a desktop\n",
    "    # Won't bother with the bucket, but will set a constant local IO path to sidestep versioning.\n",
    "    initRootFolders(\n",
    "        bucketName='', \n",
    "        localIOPath='/media/qwerty/science/science data/2017-10-18 Kaggle passenger screening/'\n",
    "    )\n",
    "\n",
    "# Name the input/output folders\n",
    "# cloud/ and local/ refer to locations defined in bucketName and localIOPath (above)\n",
    "scanDir1 = \"cloud/stage1_a3d/\"\n",
    "embeddedDir1 = \"local/embedded2D/stage1/\"\n",
    "highlightDir1 = \"local/highlight/stage1/\"\n",
    "\n",
    "scanDir2 = \"cloud/stage2_a3d/\"\n",
    "embeddedDir2 = \"local/embedded2D/stage2/\"\n",
    "\n",
    "logDir = \"local/log/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize log file\n",
    "initLog(logDir, 'embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Threshold for finding body region in 3D\n",
    "threshold3D = .0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputFiles = filenames(embeddedDir1)\n",
    "inputFiles = [f for f in inputFiles if f[-4:]=='.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bodyImages = np.array([loadFile(f) for f in inputFiles[:100]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "fig, ax = plt.subplots(1, figsize=(15,15))\n",
    "ax.imshow(bodyImages[3], cmap = 'viridis', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define rectangular image regions for body zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# 8 hyperparameters that help define body zones\n",
    "# These should be optimized\n",
    "###################################################\n",
    "\n",
    "# Leg image horizontal separations\n",
    "sock = 60\n",
    "knee = 120\n",
    "shorts = 187\n",
    "\n",
    "# Trunk image horizontal separations\n",
    "waist = 75\n",
    "chest = 200\n",
    "\n",
    "# Trunk image vertical radii\n",
    "trunkGroinRadius = 22\n",
    "legGroinRadius = 19\n",
    "chestRadius = 54\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Define body zones\n",
    "###################################################\n",
    "\n",
    "# Heights and widths of body segments in combined image\n",
    "trunkH = 360\n",
    "legH = 180\n",
    "bicepH = 90\n",
    "bicepW = 128\n",
    "forearmH = 70\n",
    "\n",
    "# Helper variables\n",
    "frontCenter = trunkH/2\n",
    "backCenter0 = int(trunkH/6)\n",
    "backCenter1 = int(trunkH*5/6)\n",
    "legShadow = 120\n",
    "\n",
    "zonesDef = {\n",
    "    1: [  # Right Bicep\n",
    "        ((trunkH + 2*legH, 0), (trunkH + 2*legH + bicepH, bicepW))\n",
    "    ],\n",
    "    2: [  # Right Forearm\n",
    "        ((trunkH + 2*legH, bicepW), (trunkH + 2*legH + forearmH, 256))\n",
    "    ],\n",
    "    3: [  # Left Bicep\n",
    "        ((trunkH + 2*legH + bicepH,0), (trunkH + 2*legH + 2*bicepH, bicepW))\n",
    "    ],\n",
    "    4: [  # Left Forearm\n",
    "        ((trunkH + 2*legH + bicepH, bicepW), (trunkH + 2*legH + bicepH + forearmH, 256))\n",
    "    ],\n",
    "    5: [  # Chest\n",
    "        ((trunkH/2 - chestRadius, chest), (trunkH/2 + chestRadius, 256))\n",
    "    ],\n",
    "    6: [ # Right abdomen\n",
    "        ((backCenter0, waist), (frontCenter, chest))    \n",
    "    ],\n",
    "    7: [ # Left abdomen\n",
    "        ((frontCenter, waist), (backCenter1, chest))\n",
    "    ],\n",
    "    8: [ # Right thigh\n",
    "        ((trunkH + legGroinRadius, shorts), (trunkH + legShadow - legGroinRadius, 256))\n",
    "    ],\n",
    "    9: [ # Groin (4 regions)\n",
    "        ((frontCenter - trunkGroinRadius, 0), (frontCenter + trunkGroinRadius, waist)),\n",
    "        ((backCenter0 - trunkGroinRadius, 0), (backCenter0 + trunkGroinRadius, waist)),\n",
    "        ((trunkH + legShadow - legGroinRadius, shorts-10), (trunkH + legShadow + legGroinRadius, 256)),\n",
    "        ((trunkH + legH + legShadow - legGroinRadius, shorts-10), (trunkH + legH + legShadow + legGroinRadius, 256)),\n",
    "    ],\n",
    "    10: [ # Left thigh\n",
    "        ((trunkH + legH + legGroinRadius, shorts), (trunkH + legH + legShadow - legGroinRadius, 256))\n",
    "    ],\n",
    "    11: [ # Right knee\n",
    "        ((trunkH, knee), (trunkH + legH, shorts))\n",
    "    ],\n",
    "    12: [ # Left knee\n",
    "        ((trunkH + legH, knee), (trunkH + 2*legH, shorts))\n",
    "    ],\n",
    "    13: [ # Right calf\n",
    "        ((trunkH, sock), (trunkH + legH, knee))\n",
    "    ],\n",
    "    14: [ # Left calf\n",
    "        ((trunkH + legH, sock), (trunkH + 2*legH, knee))\n",
    "    ],\n",
    "    15: [ # Right foot\n",
    "        ((trunkH, 0), (trunkH + legH, sock))\n",
    "    ],\n",
    "    16: [ # Left foot\n",
    "        ((trunkH + legH, 0), (trunkH + 2*legH, sock))\n",
    "    ],\n",
    "    17: [ # Upper back\n",
    "        ((backCenter0 - chestRadius, chest), (backCenter0 + chestRadius, 256))\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLabels(file):\n",
    "    \"\"\"\n",
    "    Reads a *_labels.csv file for this competition\n",
    "    Returns a list of dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = 0\n",
    "    \n",
    "    with open(file, newline='\\n') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        labels = list(reader)\n",
    "        labels = labels[1:]\n",
    "        labels = [{\n",
    "            'Id': x[0], \n",
    "            'Scan': x[0][0:32], \n",
    "            'Zone': int(x[0][37:]), \n",
    "            'Probability': int(round(float(x[1])))\n",
    "        } for x in labels]\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeLabels(file, labels):\n",
    "    \"\"\"\n",
    "    Writes a labels file for this competition.\n",
    "    Use to submit predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = [x['Id'] + ',' + str(x['Probability']) + '\\n' for x in labels]\n",
    "    \n",
    "    with open(file, 'w') as csvfile:\n",
    "        csvfile.write('Id,Probability\\n')\n",
    "        csvfile.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def selectZone(labels, zone, probability):\n",
    "    \"\"\"\n",
    "    Given a list of labels, \n",
    "    selects the rows corresponding to a given body zone, \n",
    "    with the requested probability of containing contraband.\n",
    "    probability: \n",
    "        0: no contraband\n",
    "        1: with contraband\n",
    "        -1: anything\n",
    "    \"\"\"\n",
    "    \n",
    "    out = [x for x in labels if x['Zone'] == zone and (x['Probability'] == probability or probability == -1)]\n",
    "    return out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = getLabels(filePath('local/stage1_labels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save folder of body images with contraband highlighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def highlightZone(image, zone, zonesDef):\n",
    "    \"\"\"\n",
    "    Draws a square around the requested zone on the given body image.\n",
    "    \"\"\"\n",
    "    \n",
    "    out = image.copy()\n",
    "    nx, ny, dmy = image.shape\n",
    "\n",
    "    rectangles = zonesDef[zone]\n",
    "    \n",
    "    for rect in rectangles:\n",
    "        # Get rectangle top left (start) and bottom right (end)\n",
    "        [[xStart, yStart], [xEnd, yEnd]] = np.array(rect, dtype=np.int32)\n",
    "        \n",
    "        # Clip to valid image coordinates\n",
    "        xStart = np.clip(xStart, 0, nx-1)\n",
    "        xEnd = np.clip(xEnd, 0, nx-1)\n",
    "        yStart = np.clip(yStart, 0, ny-1)\n",
    "        yEnd = np.clip(yEnd, 0, ny-1)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        out[xStart:xEnd, yStart] += 10\n",
    "        out[xStart:xEnd, yEnd] += 10\n",
    "        out[xStart, yStart:yEnd] += 10\n",
    "        out[xEnd, yStart:yEnd] += 10\n",
    "\n",
    "    return np.clip(out, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def highlightZones(file, zonesDef, labels):\n",
    "    \"\"\"\n",
    "    Loads the given body image file and highlights all the zones with contraband.\n",
    "    \"\"\"\n",
    "    \n",
    "    base = file.split('/')[-1]\n",
    "    scan = base.split('.')[-2]\n",
    "\n",
    "    lbls = [(x['Zone'], x['Probability']) for x in labels if x['Scan'] == scan]\n",
    "\n",
    "    img = loadFile(file)\n",
    "\n",
    "    for i in range(len(lbls)):\n",
    "        if lbls[i][1] == 1:\n",
    "            img = highlightZone(img, lbls[i][0], zonesDef)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def saveImage(image, outputDir, inputFile):\n",
    "    \"\"\"Saves a body image file\"\"\"\n",
    "    base = inputFile.split('/')[-1]\n",
    "    base = base.split('.')[-2]\n",
    "    outputFile = outputDir + base + '.png'\n",
    "    outputFile = filePath(outputFile)\n",
    "    imsave(outputFile, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in inputFiles:\n",
    "    img = loadFile(f)\n",
    "    img = highlightZones(f, zonesDef, labels)\n",
    "    saveImage(img, highlightDir1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract a zone's image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractZone(bodyImg, zone, zonesDef):\n",
    "    \"\"\"\n",
    "    Extracts rectangular image patches for the requested zone.\n",
    "    The sensitive area is made of multiple patches.\n",
    "    \"\"\"\n",
    "    \n",
    "    nx, ny, dmy = bodyImg.shape\n",
    "    \n",
    "    rectangles = zonesDef[zone]\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for rect in rectangles:\n",
    "        # Get rectangle top left (start) and bottom right (end)\n",
    "        [[xStart, yStart], [xEnd, yEnd]] = np.array(rect, dtype=np.int32)\n",
    "        \n",
    "        # Clip to valid image coordinates\n",
    "        xStart = np.clip(xStart, 0, nx-1)\n",
    "        xEnd = np.clip(xEnd, 0, nx)\n",
    "        yStart = np.clip(yStart, 0, ny-1)\n",
    "        yEnd = np.clip(yEnd, 0, ny)\n",
    "        \n",
    "        images.append(bodyImg[xStart:xEnd, yStart:yEnd])\n",
    "        \n",
    "    width = max([x.shape[1] for x in images])\n",
    "    \n",
    "    images = [resize(x, (len(x), width)) for x in images]\n",
    "    \n",
    "    return np.concatenate(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = bodyImages[0]\n",
    "x = extractZone(img, 15, zonesDef)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(5,5))\n",
    "ax.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get zone images for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getZoneImages(folder, scanIDs, zonesDef):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to get zone images\n",
    "    Takes list of dictionaries, each containing 'Scan' field\n",
    "        Don't need to be unique\n",
    "    Returns labels list with zone image column\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dictionary of scan images\n",
    "    uniqeScans = set([x['Scan'] for x in scanIDs])\n",
    "    bodyImages = {s: loadFile(folder + s + '.png') for s in uniqeScans}\n",
    "\n",
    "    # Init empty output if necessary\n",
    "    zonesAlreadyEnumerated = len(scanIDs) == len(zonesDef)*len(bodyImages)\n",
    "    zonesNotEnumerated = len(scanIDs) == len(bodyImages)\n",
    "    if zonesAlreadyEnumerated:\n",
    "        out = scanIDs.copy()\n",
    "    elif zonesNotEnumerated:\n",
    "        out = [\n",
    "            {\n",
    "                'Id': s + '_Zone' + str(z),\n",
    "                'Scan': s,\n",
    "                'Zone': z\n",
    "            }\n",
    "            for s in bodyImages.keys()\n",
    "            for z in range(1,18)\n",
    "        ]\n",
    "    else:\n",
    "        print('Error in getZoneImages: incorrect number of scanIDs.  Scans must either be unique or duplicated 17 times')\n",
    "        return 0\n",
    "\n",
    "    # Extract image zones\n",
    "    for d in out:\n",
    "        zoneImg = extractZone(bodyImages[d['Scan']], d['Zone'], zonesDef)\n",
    "        d['ZoneImage'] = zoneImg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = getZoneImages(embeddedDir1, labels, zonesDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = labels[6]\n",
    "print('Zone: ', l['Zone'], '\\nProbability:', l['Probability'])\n",
    "fig, ax = plt.subplots(1, figsize=(5,5))\n",
    "ax.imshow(l['ZoneImage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize normal variation with SVD, subtract as background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class imageDimensionalityReducer():\n",
    "    \"\"\"\n",
    "    Performs PCA on a list of monochromatic images.\n",
    "    The reduce method projects images onto the basis of the most significant principal components.\n",
    "    The list of images should have dimensions (n,height,width)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, numSV=15):\n",
    "        self.numSV = numSV\n",
    "    \n",
    "    def fit(self, images):\n",
    "\n",
    "        # Get a copy\n",
    "        imgs = images.copy()\n",
    "        \n",
    "        # Zero-center the images\n",
    "        imgs -= 0.5\n",
    "\n",
    "        # Get list of flattened full-size images\n",
    "        matFull = np.reshape(imgs, (imgs.shape[0], -1))\n",
    "\n",
    "        # Get list of flattened small images\n",
    "        # This will speed up calculation of the correlation matrix\n",
    "        mat = np.array([resize(x, (30,30)) for x in imgs])\n",
    "        mat = np.reshape(mat, (mat.shape[0], -1))\n",
    "\n",
    "        # Get correlation matrix\n",
    "        cor = np.dot(mat, np.transpose(mat))\n",
    "\n",
    "        # Get eigenbasis for column space of mat\n",
    "        evals, evecs = linalg.eig(cor)\n",
    "\n",
    "        # Get most significant eigenvectors\n",
    "        evecs = np.real(evecs[:, :self.numSV])\n",
    "\n",
    "        # Approximate the right singular vectors for matFull\n",
    "        # (evecs.rightSV ~= matFull), and then normalize rightSV\n",
    "        rightSV = np.dot(linalg.pinv(evecs), matFull)\n",
    "        self.rightSV = np.array([x/linalg.norm(x) for x in rightSV])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def reduce(self, images):\n",
    "        \n",
    "        # Get a copy\n",
    "        imgs = images.copy()\n",
    "        \n",
    "        # Zero-center the images\n",
    "        imgs -= 0.5\n",
    "        \n",
    "        # Get eigenimage basis expansion coefficients\n",
    "        imgsLow = np.reshape(imgs, (len(imgs), -1)).dot(np.transpose(self.rightSV)).dot(self.rightSV)\n",
    "        imgsLow = np.reshape(imgsLow, imgs.shape)\n",
    "        \n",
    "        return imgsLow + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class imageBackgroundSubtractor():\n",
    "    \"\"\"\n",
    "    Uses PCA to estimate a background for a list of images (using imageDimensionalityReducer).\n",
    "    The subtract method subtracts the estimated background from the list of images.\n",
    "    The list of images should have dimensions (n,height,width,3)\n",
    "    Initialization variables:\n",
    "        channelMask: Binary list of length three.  Selects channels to receive background subtractions.\n",
    "        channelRescale:  Adjust saturation.  1 -> no adjustment\n",
    "        numSV: Number of singular values to use in background subtraction\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, channelMask, channelRescale, numSV=15):\n",
    "        self.channelMask = channelMask\n",
    "        self.numSV = numSV\n",
    "        self.channelRescale = channelRescale\n",
    "\n",
    "    def fit(self, images):\n",
    "\n",
    "        estimators = self.channelMask.copy()\n",
    "\n",
    "        for i in range(len(self.channelMask)):\n",
    "            if self.channelMask[i]:\n",
    "                estimators[i] = imageDimensionalityReducer(self.numSV)\n",
    "                estimators[i].fit(images[:,:,:,i])\n",
    "\n",
    "        # Save results\n",
    "        self.estimators = estimators\n",
    "\n",
    "        return self\n",
    "\n",
    "    def subtract(self, images):\n",
    "\n",
    "        bg = images.copy()\n",
    "\n",
    "        for i, est in enumerate(self.estimators):\n",
    "            if self.channelMask[i]:\n",
    "                bg[:,:,:,i] = est.reduce(images[:,:,:,i])\n",
    "            else:\n",
    "                bg[:,:,:,i] = 0.5\n",
    "\n",
    "        subtracted = images - bg + 0.5\n",
    "        \n",
    "        for i in range(len(self.channelRescale)):\n",
    "            subtracted[:,:,:,i] = (subtracted[:,:,:,i] - 0.5) * self.channelRescale[i] + 0.5\n",
    "        \n",
    "        subtracted = np.clip(subtracted, 0, 1)\n",
    "\n",
    "        return subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zone = 15\n",
    "\n",
    "# Get images of zones without threats\n",
    "imgsEmpty = np.array([x['ZoneImage'] for x in selectZone(labels, zone, 0)[:1000]])\n",
    "\n",
    "# Get files with threat\n",
    "imgsThreat = np.array([x['ZoneImage'] for x in selectZone(labels, zone, 1)[:1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit background subtractor\n",
    "bgs = imageBackgroundSubtractor([1,1,1], [1.5,1.5,1.5], numSV=4)\n",
    "bgs.fit(imgsEmpty)\n",
    "\n",
    "# Subtract background\n",
    "nobgEmpty = bgs.subtract(imgsEmpty)\n",
    "nobgThreat= bgs.subtract(imgsThreat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clampShadow(bodyImages, bodyNoBG, scale):\n",
    "    \n",
    "    # In shadow regions, the surface isn't captured, so surface radius and intensity tend to be junk.\n",
    "    # The blue channel is surface thickness, and tends to be high in shadow regions.\n",
    "    # Wherever blue is explainable background (I.e. it got subtracted), it's probably a shadow region,\n",
    "    # so clamp the other colors to grey.\n",
    "    \n",
    "    blueDiff = bodyNoBG[:,:,:,2] - bodyImages[:,:,:,2]\n",
    "    \n",
    "    clamp = np.exp(blueDiff/scale)\n",
    "    clamp = np.clip(clamp, 0, 1)\n",
    "    \n",
    "    out = bodyNoBG.copy()\n",
    "    out[:,:,:,0] = (out[:,:,:,0] - 0.5) * clamp * 2.5 + 0.5\n",
    "    out[:,:,:,1] = (out[:,:,:,1] - 0.5) * clamp * 2.5 + 0.5\n",
    "    out = np.clip(out, 0, 1)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clampedEmpty =  clampShadow(imgsEmpty, nobgEmpty, 0.2)\n",
    "clampedThreat =  clampShadow(imgsThreat, nobgThreat, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Background subtraction works well\n",
    "\n",
    "fig, ax = plt.subplots(6,3, figsize=(13,9), facecolor='white')\n",
    "\n",
    "ax[0,0].set_title('1. Original surface moments', size='large')\n",
    "ax[0,1].set_title('2. Background subtracted', size='large')\n",
    "ax[0,2].set_title('3. Shadows clamped', size='large')\n",
    "\n",
    "for i in range(6):\n",
    "  \n",
    "    ax[i,0].imshow(np.transpose(imgsThreat[i], axes=(1,0,2))[::-1])\n",
    "    ax[i,0].set_yticklabels([])\n",
    "    ax[i,0].set_xticklabels([])\n",
    "    \n",
    "    ax[i,1].imshow(np.transpose(nobgThreat[i], axes=(1,0,2))[::-1])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,1].set_xticklabels([])\n",
    "    \n",
    "    ax[i,2].imshow(np.transpose(clampedThreat[i], axes=(1,0,2))[::-1])\n",
    "    ax[i,2].set_yticklabels([])\n",
    "    ax[i,2].set_xticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtract background for all zone images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class zoneBackgroundSubtractor():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.numZones = 17\n",
    "\n",
    "    def fit(self, dataset):\n",
    "\n",
    "        self.subtractors = [[] for x in range(self.numZones)]\n",
    "\n",
    "        for z in range(1, self.numZones+1):\n",
    "            print('Fitting background subtractor for zone: ', z)\n",
    "\n",
    "            # Fit background subtractor\n",
    "            # Use zone images without contraband\n",
    "            zoneEmpty = selectZone(dataset, z, 0)\n",
    "            zoneEmpty = np.array([d['ZoneImage'] for d in zoneEmpty])\n",
    "            bgsubtractor = imageBackgroundSubtractor([1,1,1], [1.5,1.5,1.5], numSV=4)\n",
    "            bgsubtractor.fit(zoneEmpty)\n",
    "\n",
    "            # Save\n",
    "            self.subtractors[z-1] = bgsubtractor\n",
    "\n",
    "        return self\n",
    "\n",
    "    def subtract(self, dataset):\n",
    "\n",
    "        out = []\n",
    "        \n",
    "        for z in range(1, self.numZones+1):\n",
    "            print('Subtracting background in zone: ', z)\n",
    "            \n",
    "            bgsubtractor = self.subtractors[z-1]\n",
    "            \n",
    "            # Get images\n",
    "            zoneData = selectZone(dataset, z, -1).copy()\n",
    "            x = np.array([d['ZoneImage'] for d in zoneData])\n",
    "\n",
    "            # Subtract background\n",
    "            nobg = bgsubtractor.subtract(x)\n",
    "            \n",
    "            # Clamp to grey in shadow regions\n",
    "            x = clampShadow(x, nobg, 0.2)\n",
    "            #x = nobg\n",
    "\n",
    "            for i in range(len(zoneData)):\n",
    "                zoneData[i]['ZoneImageBGSubtracted'] = x[i]\n",
    "\n",
    "            out = out + zoneData\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgSubtractor = zoneBackgroundSubtractor()\n",
    "bgSubtractor.fit(labels)\n",
    "labels = bgSubtractor.subtract(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zone = 15\n",
    "imgsThreat = np.array([x['ZoneImageBGSubtracted'] for x in selectZone(labels, zone, 1)[:100]])\n",
    "imgsEmpty = np.array([x['ZoneImageBGSubtracted'] for x in selectZone(labels, zone, 0)[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,2, figsize=(7,9), facecolor='white')\n",
    "\n",
    "ax[0,0].set_title('No contraband', size='large')\n",
    "ax[0,1].set_title('With contraband', size='large')\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    ax[i,0].imshow(np.transpose(imgsEmpty[i], axes=(1,0,2))[::-1])\n",
    "    ax[i,0].set_yticklabels([])\n",
    "    ax[i,0].set_xticklabels([])\n",
    "    \n",
    "    ax[i,1].imshow(np.transpose(imgsThreat[i], axes=(1,0,2))[::-1])\n",
    "    ax[i,1].set_yticklabels([])\n",
    "    ax[i,1].set_xticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning: get bottleneck features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 20 minutes. Your machine should have least 8 cores, 48GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip3 install Keras\n",
    "!pip3 install H5py\n",
    "\n",
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bottleneck(dataset):\n",
    "\n",
    "    size = (139,139,3)\n",
    "    print(str(datetime.datetime.now()) + \"    Started bottleneck layer calculation\")\n",
    "\n",
    "    print('Loading model')\n",
    "    model = InceptionV3(weights='imagenet', include_top=False, input_shape=size)\n",
    "\n",
    "    print('Resizing images')\n",
    "    imgs = np.array([resize(x['ZoneImageBGSubtracted'], size).astype(np.float32) for x in dataset])\n",
    "\n",
    "    print('Preprocessing images')\n",
    "    preprocessed = preprocess_input(imgs)\n",
    "\n",
    "    print('Extracting bottleneck features')\n",
    "    features = model.predict(preprocessed)\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    print('Pooling')\n",
    "    features = np.mean(features, axis=(1,2))\n",
    "\n",
    "    #print('Flattening')\n",
    "    #features = np.reshape(features, (len(features), -1))\n",
    "\n",
    "    print('Storing bottleneck features')\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]['Bottleneck'] = features[i]\n",
    "\n",
    "    print(str(datetime.datetime.now()) + \"    Finished bottleneck layer calculation\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = bottleneck(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logLossScoreWithEstimator(estimator, x, y):\n",
    "    pred = estimator.predict_proba(x)[:,1]\n",
    "    #pred =  estimator.predict(x)\n",
    "    delta = .07\n",
    "    pred = np.clip(np.array(pred, dtype=np.float32), delta, 1-delta)\n",
    "    score = -((np.dot(y, np.log(pred))) + (np.dot(1-np.array(y), np.log(1-pred))))/len(y)\n",
    "    return score\n",
    "\n",
    "def logLossScoreSimple(pred, y, delta=0.07):\n",
    "\n",
    "    pred = np.clip(np.array(pred, dtype=np.float32), delta, 1-delta)\n",
    "    score = -((np.dot(y, np.log(pred))) + (np.dot(1-np.array(y), np.log(1-pred))))/len(y)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class threatPredicter():\n",
    "    \"\"\"\n",
    "    Binary classifier which can be applied directly to label datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.numZones = 17\n",
    "\n",
    "    def fit(self, dataset):\n",
    "\n",
    "        self.pipelines = [[] for x in range(self.numZones)]\n",
    "\n",
    "        for z in range(1, self.numZones+1):\n",
    "            print('Fitting zone ', z)\n",
    "\n",
    "            # Get data for the zone being fitted\n",
    "            zoneData = selectZone(dataset, z, -1)\n",
    "            \n",
    "            # Get x (bottleneck features)\n",
    "            x = np.array([d['Bottleneck'] for d in zoneData])\n",
    "            \n",
    "            # Get y (contraband probabilities)\n",
    "            y = [d['Probability'] for d in zoneData]\n",
    "\n",
    "            # Fit regressor\n",
    "            #regressor = RandomForestClassifier() \n",
    "            regressor = LogisticRegression()\n",
    "            regressor.fit(x, y)\n",
    "\n",
    "            # Save pipeline\n",
    "            self.pipelines[z-1] = regressor\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, dataset):\n",
    "\n",
    "        out = []\n",
    "\n",
    "        for z in range(1, self.numZones+1):\n",
    "            print('Predicting zone ', z)\n",
    "\n",
    "            regressor = self.pipelines[z-1]\n",
    "            \n",
    "            # Get bottleneck features for this zone\n",
    "            zoneData = selectZone(dataset, z, -1).copy()\n",
    "            x = np.array([d['Bottleneck'] for d in zoneData])\n",
    "\n",
    "            # Predict\n",
    "            pred = regressor.predict_proba(x)[:,1]\n",
    "            #pred = regressor.predict(x)\n",
    "\n",
    "            for i in range(len(zoneData)):\n",
    "                zoneData[i]['Probability'] = pred[i]\n",
    "\n",
    "            out = out + zoneData\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on stage 1 train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = threatPredicter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions for stage 1 test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsTest = getLabels(filePath('local/stage1_sample_submission.csv'))\n",
    "labelsTest = getZoneImages(embeddedDir1, labelsTest, zonesDef)\n",
    "labelsTest = bgSubtractor.subtract(labelsTest)\n",
    "labelsTest = bottleneck(labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict(labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = [a['Probability'] for a in pred]\n",
    "fig, ax = plt.subplots(1,facecolor='white')\n",
    "ax.plot(prob)\n",
    "ax.set_ylabel('Predicted probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -50\n",
    "\n",
    "order = np.argsort(prob)\n",
    "img = pred[order[i]]['ZoneImageBGSubtracted']\n",
    "print(pred[order[i]]['Probability'])\n",
    "fig, ax = plt.subplots(1, figsize=(5,5))\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with solution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsSolution = getLabels(filePath('local/stage1_solution.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sortLabels(labels):\n",
    "    ids = [l['Id'] for l in labels]\n",
    "    order = np.argsort(ids)\n",
    "    out = [deepcopy(labels[order[i]]) for i in range(len(order))]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = sortLabels(pred)\n",
    "p = [x['Probability'] for x in p]\n",
    "\n",
    "s = sortLabels(labelsSolution)\n",
    "s = [x['Probability'] for x in s]\n",
    "\n",
    "print('Num positives in test dataset: ', np.sum(s))\n",
    "print('Score: ', logLossScoreSimple(p, s, .02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions for stage 2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 25 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels2 = getLabels(filePath('local/stage2_sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels2 = getZoneImages(embeddedDir2, labels2, zonesDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels2 = bgSubtractor.subtract(labels2)\n",
    "labels2 = bottleneck(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred2 = model.predict(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clip slightly for safety. (Exact predictions give huge errors when they're wrong.)\n",
    "pred2b = deepcopy(pred2)\n",
    "for i in range(len(pred2b)):\n",
    "    pred2b[i]['Probability'] = np.clip(pred2b[i]['Probability'], .02, 1-.02)\n",
    "\n",
    "# Plot clipped predictions\n",
    "prob = [a['Probability'] for a in pred2b]\n",
    "plt.plot(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writeLabels(filePath('local/transferLearningAvgPool.csv'), pred2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(datetime.datetime.now()) + \"    Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
